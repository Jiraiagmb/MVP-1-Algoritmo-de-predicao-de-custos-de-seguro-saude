{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jiraiagmb/MVP-1-Algoritmo-de-predicao-de-custos-de-seguro-saude/blob/main/MVP_1_insurance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNq-XQWWYNXh"
      },
      "source": [
        "# **MVP 1 - Algoritmo de predição de custos de seguro saúde**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Gabriel Borges da Conceição e Guilherme Missaggia Bertolo**\n",
        "\n",
        "**29/09/2025**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Definição do problema\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "O dataset contém informações de 1338 indivíduos, incluindo variáveis demográficas e de saúde, como idade, sexo, índice de massa corporal (IMC), número de filhos, hábito de fumar e região de residência. O objetivo é analisar como esses fatores influenciam o custo do seguro saúde e desenvolver um modelo capaz de prever o valor das taxas de seguro para novos indivíduos.\n",
        "\n",
        "O desafio consiste em estimar o valor dessas taxas a partir das características fornecidas, analisando como cada fator influencia no custo final. Esse cenário foi formalizado como um problema de regressão supervisionada utilizando técnicas de Machine Learning.\n",
        "\n",
        "##Premissas\n",
        "Assume-se que existe uma relação sistemática entre as variáveis independentes e a variável alvo, de forma que os padrões podem ser aprendidos por um modelo supervisionado. Também se considera que os dados são de qualidade suficiente, representativos da população e sem vieses que comprometam sua utilização, além de que os registros são independentes entre si, ou seja, o custo de seguro de um indivíduo não influencia diretamente o de outro. Outro ponto assumido é que as variáveis disponíveis no conjunto de dados são relevantes e suficientes para explicar uma parte significativa da variabilidade nos custos, e que essas relações permanecem estáveis ao longo do tempo, possibilitando a generalização do modelo.\n",
        "\n",
        "##Dataset\n",
        "\n",
        "\n",
        "*   Fonte: Kaggle\n",
        "*   Link: https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset\n",
        "*   Atributos: O dataset possui 6 variáveis independentes (idade, sexo, IMC, dependentes, htabagismo e região demográfica) e uma variável dependente custo do seguro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnVZXG7QY1D2"
      },
      "source": [
        "## **1. Importando bibliotecas**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4i2iuTlZYvQ"
      },
      "outputs": [],
      "source": [
        "! pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf73M_f9XwZ7"
      },
      "outputs": [],
      "source": [
        "# Manipulação de dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Visualização\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Leitura de arquivos\n",
        "import csv\n",
        "from pandas import read_excel\n",
        "\n",
        "# Google Colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Modelagem\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# LazyPredict\n",
        "from lazypredict.Supervised import LazyRegressor, LazyClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUGwBVH7Y8Rq"
      },
      "source": [
        "## **2. Lendo o dataset**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "O dataset é lido no Google Drive. No caminho Meu Drive/insurance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVojHjyWZC9D"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive') # Montar arquivos do Google Drive\n",
        "\n",
        "# Especificando o local onde os dados estão salvos\n",
        "proj_path = '/content/gdrive/MyDrive/insurance/'\n",
        "\n",
        "#Especificando dados sobre o arquivo\n",
        "ac_sheet = 'insurance'\n",
        "file_name1 = 'insurance.xlsx'\n",
        "df = read_excel(proj_path + file_name1, sheet_name = ac_sheet)\n",
        "#df1 = df1.sample(frac=0.3, random_state=42)\n",
        "n_row1 = df.shape[0] # Numero de linhas\n",
        "print('Numero Registros:',n_row1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-WQte9blsyQ"
      },
      "source": [
        "## **3. Preparação dos dados**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Para a aplicação dos algoritmos de aprendizado de máquina, foi necessário realizar a etapa de pré-processamento, garantindo que todas as variáveis estivessem em formato numérico e adequadas para o treinamento dos modelos.\n",
        "Os números inteiros foram transformados em números reais e as variáveis categóricas também foram convertidas para o tipo float, assegurando uniformidade no conjunto de dados. Por fim, foram removidas as linhas contendo valores ausentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZrXzR1QlsyR"
      },
      "outputs": [],
      "source": [
        "df = df.astype({'age':'float'})\n",
        "df = df.astype({'bmi':'float'})\n",
        "df = df.astype({'children':'float'})\n",
        "df['sex'] = df['sex'].map({'female': 2, 'male': 1}).astype(float)\n",
        "df['smoker'] = df['smoker'].map({'no': 2, 'yes': 1}).astype(float)\n",
        "df['region'] = df['region'].map({\n",
        "    'southwest': 1,\n",
        "    'southeast': 2,\n",
        "    'northwest': 3,\n",
        "    'northeast': 4\n",
        "}).astype(float)\n",
        "\n",
        "df = df.dropna()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xA0F9ClsyT"
      },
      "source": [
        "### **4. Separando as variáveis independentes (X) da variável alvo (Y)**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Todas as colunas do DataFrame, exceto charges, foram atribuídas à variável X, representando os atributos que servirão como entrada para o modelo. A coluna charges foi separada na variável Y, correspondendo à variável que se deseja prever.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbTq4zzKZpVf"
      },
      "outputs": [],
      "source": [
        "X = df.drop('charges', axis=1)\n",
        "Y = df.charges\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Selecionando melhores atributos**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Esse código aplica uma técnica de seleção de atributos para identificar quais variáveis têm maior influência sobre a variável alvo (custo do seguro saúde).\n",
        "\n",
        "O código está comentado porque não obtivemos um resultado vantajoso reduzindo o número de atributos."
      ],
      "metadata": {
        "id": "ZHpmOKyp9WfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#names=list(X.columns)\n",
        "## Seleção de atributos\n",
        "#n_selected=4 # Digitar aqui o número de atributos a serem selecionados\n",
        "#test = SelectKBest(score_func=f_regression, k=n_selected)\n",
        "#fit = test.fit(X, Y)\n",
        "## summarize scores\n",
        "#np.set_printoptions(precision=3)\n",
        "#features = fit.transform(X)\n",
        "## list(data) or\n",
        "#performance_list = pd.DataFrame(\n",
        "#    {'Attribute': names,\n",
        "#     'Value': fit.scores_\n",
        "#    })\n",
        "#performance_list=performance_list.sort_values(by=['Value'], ascending=False)\n",
        "#names_selected=performance_list.values[0:n_selected,0]\n",
        "\n",
        "#XX = pd.DataFrame (X, columns = names_selected)\n",
        "#X=XX\n",
        "#X"
      ],
      "metadata": {
        "id": "xRbsTMBM9Wn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n432oh1-lsyU"
      },
      "source": [
        "## **6. Dividindo dataset em treino e teste**\n",
        "---\n",
        "\n",
        "\n",
        "O código separa os dados em treino (70%) e teste (30%) para que o modelo possa ser treinado em uma parte dos dados e avaliado em dados que ele ainda não conhece."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYck-_XeaHNZ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROL3fIr5u5el"
      },
      "source": [
        "## **7. Compare ML algoritmos usando lazyregressor**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "O código automatiza a comparação de múltiplos modelos de regressão, fornecendo rapidamente métricas de desempenho (R², RMSE, tempo de treino), permitindo identificar quais algoritmos funcionam melhor para o dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9cGnBzbu5wN"
      },
      "outputs": [],
      "source": [
        "# Defines and builds the lazyregressor\n",
        "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = reg.fit(X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "print(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NSwXbRWyCYj"
      },
      "source": [
        "## **8. Otimizando o melhor modelo usando o algoritmo Random Forest Regressor**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "O algoritmo testa várias combinações de parâmetros do modelo (hiperparâmetros) e, para cada combinação, avaliar seu desempenho de forma confiável usando validação cruzada, escolhendo no final a configuração que obtém os melhores resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QHISG0IuA7o"
      },
      "outputs": [],
      "source": [
        "# Parâmetros para tunar\n",
        "param = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2] }\n",
        "\n",
        "# Definir o GridSearchCV com RandomForestRegressor\n",
        "model = GridSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=42),\n",
        "    param_grid=param,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Previsões no mesmo conjunto\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# R²\n",
        "r2 = r2_score(Y, y_pred)\n",
        "\n",
        "# R² Ajustado\n",
        "n = X.shape[0] # número de observações\n",
        "p = X.shape[1] # número de features\n",
        "r2_ajustado = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "# RMSE\n",
        "rmse = np.sqrt(mean_squared_error(Y, y_pred))\n",
        "\n",
        "# Imprimir resultados\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"R² Ajustado: {r2_ajustado:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GpB0h7ulsyV"
      },
      "source": [
        "## **9. Otimizando o melhor modelo usando o algoritmo Gradient Boosting Regressor**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "O algoritmo testa várias combinações de parâmetros do modelo (hiperparâmetros) e, para cada combinação, avaliar seu desempenho de forma confiável usando validação cruzada, escolhendo no final a configuração que obtém os melhores resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiFHFXq5-h62"
      },
      "outputs": [],
      "source": [
        "# Parâmetros para tunar\n",
        "param = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Definir o GridSearchCV com GradientBoostingRegressor\n",
        "model = GridSearchCV(\n",
        "    estimator=GradientBoostingRegressor(random_state=42),\n",
        "    param_grid=param,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Previsões no mesmo conjunto\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# R²\n",
        "r2 = r2_score(Y, y_pred)\n",
        "\n",
        "# R² Ajustado\n",
        "n = X.shape[0]  # número de observações\n",
        "p = X.shape[1]  # número de features\n",
        "r2_ajustado = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "# RMSE\n",
        "rmse = np.sqrt(mean_squared_error(Y, y_pred))\n",
        "\n",
        "# Imprimir resultados\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"Adjusted R²: {r2_ajustado:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10. Conclusão**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "O estudo demonstrou que variáveis como idade, IMC, número de dependentes, hábito de fumar, sexo e região exercem impacto relevante nos custos do seguro saúde. A partir da aplicação de modelos de aprendizado de máquina, buscou-se identificar quais técnicas apresentariam melhor capacidade de generalização.\n",
        "\n",
        "Nos primeiros testes, modelos como Poisson Regressor, Gradient Boosting Regressor e Random Forest Regressor apresentaram baixo poder explicativo, com valores de R² entre 0,21 e 0,30. Posteriormente, ao aplicar técnicas de otimização, foi obtido um resultado expressivamente superior, com R² de 0,7177 e R² ajustado de 0,7165, utilizando o algoritmo Random Forest Regressor, explicando cerca de 71% da variabilidade dos custos. No entanto, nem todos os ajustes levaram a melhorias consistentes: utilizando o algoritmo Gradient Boosting Regressor, o modelo alcançou R² de 0,4963 (ajustado 0,4940), desempenho intermediário entre os experimentos.\n",
        "\n",
        "Esses resultados evidenciam que a escolha do algoritmo e de sua parametrização é determinante para a qualidade das previsões. Embora o melhor modelo tenha alcançado desempenho satisfatório, ainda há espaço para aprimoramentos, especialmente considerando o RMSE elevado, que indica grande dispersão nos valores previstos.\n",
        "\n",
        "Conclui-se que, apesar de limitações como a ausência de variáveis clínicas detalhadas e a suposição de independência entre registros, a modelagem proposta mostra potencial para apoiar processos de precificação de seguros de saúde.\n",
        "\n",
        "Para trabalhos futuros, recomenda-se o uso de bases mais completas, bem como a avaliação de modelos mais robustos, como redes neurais profundas ou ensembles avançados, visando reduzir erros e aumentar a capacidade preditiva."
      ],
      "metadata": {
        "id": "0ftaD4iny2kZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}